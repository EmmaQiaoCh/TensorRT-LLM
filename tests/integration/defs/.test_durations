{
   "accuracy/test_cli_flow.py::TestLlama2_7B::test_fp8": 386.2442155708559,
   "examples/test_gemma.py::test_hf_gemma_fp8_base_bf16_multi_lora[gemma-2-9b-it]": 237.9742201359477,
   "examples/test_llama.py::test_llama_3_x_fp8_with_bf16_lora[llama-3.1-8b]": 142.68067401414737,
   "examples/test_qwen.py::test_llm_hf_qwen_multi_lora_1gpu[qwen2.5_1.5b_instruct]": 136.33865520101972,
   "test_e2e.py::test_mistral_large_hidden_vocab_size": 72.02068409905769,
   "test_e2e.py::test_trtllm_bench_help_sanity[meta-llama/Llama-3.1-8B]": 85.78541125101037,
   "test_e2e.py::test_trtllm_bench_iteration_log[TRT-streaming-meta-llama/Llama-3.1-8B-llama-3.1-model/Meta-Llama-3.1-8B]": 240.02591652004048,
   "- fp16 and fp8 to test quantization\"": 362.7472623869544,
   "test_unittests.py::test_unittests_v2[unittest/llmapi/test_llm_quant.py]": 271.31969389499864,
   "test_unittests.py::test_unittests_v2[unittest/trt/attention/test_gpt_attention.py -k \"xqa_generic\"]": 558.075757034123,
   "test_unittests.py::test_unittests_v2[unittest/trt/model_api/test_model_level_api.py]": 258.148328371346,
   "accuracy/test_cli_flow.py::TestLlama3_1_8BInstruct::test_fp8_prequantized": 676.9024513908662,
   "accuracy/test_cli_flow.py::TestVicuna7B::test_medusa[cuda_graph]": 924.2287790179253,
   "examples/test_medusa.py::test_llm_medusa_with_qaunt_base_model_1gpu[fp8-use_cpp_session-medusa-vicuna-7b-v1.3-4-heads-float16-bs1]": 2204.1166265308857,
   "examples/test_multimodal.py::test_llm_multimodal_general[Llama-3.2-11B-Vision-pp:1-tp:1-bfloat16-bs:1-cpp_e2e:False-nb:1]": 462.35524883680046,
   "test_e2e.py::test_trtllm_bench_iteration_log[TRT-non-streaming-meta-llama/Llama-3.1-8B-llama-3.1-model/Meta-Llama-3.1-8B]": 481.20551520911977,
   "test_unittests.py::test_unittests_v2[unittest/test_model_runner_cpp.py]": 1217.3188257664442,
   "test_unittests.py::test_unittests_v2[unittest/trt/model/eagle]": 99.2543628886342,
   "test_unittests.py::test_unittests_v2[unittest/trt/model_api/test_model_api_multi_gpu.py]": 32.14892394840717,
   "test_unittests.py::test_unittests_v2[unittest/trt/quantization/test_weight_only_quant_matmul.py]": 127.42656641220674,
   "perf/test_perf.py::test_perf[bert_base-cpp-ootb-float16-bs:32-input_len:32]": 83.58070359751582,
   "perf/test_perf.py::test_perf[bert_base-cpp-plugin-float16-bs:32-input_len:32]": 73.46264676377177,
   "perf/test_perf.py::test_perf[bert_base-ootb-float16-bs:32-input_len:32]": 90.59760595485568,
   "perf/test_perf.py::test_perf[bert_base-plugin-float16-bs:32-input_len:32]": 83.6641127448529,
   "perf/test_perf.py::test_perf[gpt_350m-cppmanager-plugin_ifb-float16-bs:32-input_output_len:60": 71.86463450547308,
   "perf/test_perf.py::test_perf[gpt_350m-cppmanager-plugin_ifb-float16-gwp:0.0-bs:32-input_output_len:60": 72.86612248793244,
   "perf/test_perf.py::test_perf[gpt_350m-cppmanager-static_batching-plugin_ifb-float16-bs:32-input_output_len:60": 73.87707364559174,
   "perf/test_perf.py::test_perf[gpt_350m-ootb-float16-bs:32-input_output_len:60": 117.86459614243358,
   "perf/test_perf.py::test_perf[gpt_350m-ootb-float16-gwp:0.5-bs:32-input_output_len:60": 118.89629319962114,
   "perf/test_perf.py::test_perf[gpt_350m-plugin-float16-bs:32-input_output_len:60": 155.10736517980695,
   "perf/test_perf.py::test_perf[roberta_base-cpp-plugin-float16-bs:32-input_len:128+512]": 112.65741018950939,
   "accuracy/test_cli_flow.py::TestMamba130M::test_auto_dtype": 159.90093383099884,
   "accuracy/test_cli_flow.py::TestVicuna7B::test_eagle[]": 418.4948197766207,
   "accuracy/test_cli_flow.py::TestVicuna7B::test_lookahead": 333.8107811519876,
   "examples/test_mamba.py::test_llm_mamba_1gpu[mamba-codestral-7B-v0.1-float16-enable_gemm_plugin]": 347.43300298042595,
   "examples/test_mamba.py::test_llm_mamba_1gpu[mamba2-130m-float16-enable_gemm_plugin]": 111.47361202724278,
   "examples/test_whisper.py::test_llm_whisper_general[large-v3-disable_gemm_plugin-enable_attention_plugin-disable_weight_only-float16-nb:1-use_cpp_runtime]": 221.18994572386146,
   "test_mode: Test mode (\"stress-test\" or \"stress-stage-alone\")\"": 1257.2836316861212,
   "test_e2e.py::test_openai_chat_example": 828.7512983828783,
   "test_e2e.py::test_trtllm_serve_example": 188.78006284311414,
   "test_unittests.py::test_unittests_v2[unittest/llmapi/test_llm_utils.py]": 108.81159158423543,
   "test_unittests.py::test_unittests_v2[unittest/trt/attention/test_gpt_attention_no_cache.py]": 41.4464595078025,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_fp8_block_scales[-attention_dp-cuda_graph-overlap_scheduler]": 500.55040028481744,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_fp8_block_scales[-cuda_graph]": 158.00196751998737,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_fp8_block_scales[mtp_nextn=2-]": 145.44000219507143,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_fp8_block_scales[mtp_nextn=2-attention_dp]": 142.61280856188387,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_fp8_block_scales[mtp_nextn=2-overlap_scheduler]": 141.5916840150021,
   "accuracy/test_llm_api_pytorch.py::TestLlama3_1_8BInstruct::test_bfloat16[attn_backend=FLASHINFER-]": 306.72867901809514,
   "accuracy/test_llm_api_pytorch.py::TestLlama3_1_8BInstruct::test_bfloat16[attn_backend=TRTLLM-]": 129.6755685659591,
   "accuracy/test_llm_api_pytorch.py::TestLlama3_1_8BInstruct::test_fp8[-attn_backend=FLASHINFER-torch_compile]": 224.36890634614974,
   "accuracy/test_llm_api_pytorch.py::TestLlama3_1_8BInstruct::test_fp8[-attn_backend=TRTLLM-torch_compile]": 174.40621356014162,
   "accuracy/test_llm_api_pytorch.py::TestLlama3_1_8BInstruct::test_fp8[fp8kv-attn_backend=FLASHINFER-torch_compile]": 250.0149193368852,
   "accuracy/test_llm_api_pytorch.py::TestLlama3_1_8BInstruct::test_fp8[fp8kv-attn_backend=TRTLLM-torch_compile]": 165.06079052900895,
   "disaggregated/test_disaggregated.py::test_disaggregated_deepseek_v3_lite_fp8_tp1_single_gpu[DeepSeek-V3-Lite-fp8]": 92.76344213704579,
   "disaggregated/test_disaggregated.py::test_disaggregated_deepseek_v3_lite_fp8_ucx_tp1_single_gpu[DeepSeek-V3-Lite-fp8]": 87.60457650618628,
   "disaggregated/test_disaggregated.py::test_disaggregated_load_balance[TinyLlama-1.1B-Chat-v1.0]": 46.08281739288941,
   "disaggregated/test_disaggregated_single_gpu.py::test_disaggregated_simple_deepseek[False-True-DeepSeek-V3-Lite-fp8/fp8]": 44.05157815502025,
   "disaggregated/test_disaggregated_single_gpu.py::test_disaggregated_simple_deepseek[True-True-DeepSeek-V3-Lite-fp8/fp8]": 65.79525701585226,
   "disaggregated/test_disaggregated_single_gpu.py::test_disaggregated_simple_llama[False-True-TinyLlama-1.1B-Chat-v1.0]": 23.30441342899576,
   "disaggregated/test_disaggregated_single_gpu.py::test_disaggregated_simple_llama[True-True-TinyLlama-1.1B-Chat-v1.0]": 38.36221818602644,
   "test_e2e.py::test_trtllm_bench_pytorch_backend_sanity[meta-llama/Llama-3.1-8B-llama-3.1-8b-False-False]": 82.49319917801768,
   "test_unittests.py::test_unittests_v2[unittest/_torch -k \"not (modeling or multi_gpu or auto_deploy)\"]": 1083.5048434659839,
   "test_unittests.py::test_unittests_v2[unittest/_torch/modeling -k \"modeling_mixtral\"]": 206.9945377483964,
   "accuracy/test_cli_flow.py::TestLlama7B::test_manage_weights": 584.3090210435912,
   "examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-t5-small-float32-disable_gemm_plugin-disable_attention_plugin-disable_paged_kv_cache-tp:1-pp:1-nb:1-disable_fp8]": 228.48270317539573,
   "examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-t5-small-float32-enable_gemm_plugin-enable_attention_plugin-enable_paged_kv_cache-tp:1-pp:1-nb:2-disable_fp8]": 220.61570218857378,
   "examples/test_exaone.py::test_llm_exaone_1gpu[disable_weight_only-exaone_3.0_7.8b_instruct-float16-nb:4]": 386.03687173407525,
   "examples/test_gpt.py::test_llm_gpt2_medium_bad_words_1gpu[streaming-use_cpp_session]": 204.04206707142293,
   "examples/test_gpt.py::test_llm_gpt2_medium_stop_words_1gpu[non_streaming-use_cpp_session]": 207.10212700627744,
   "examples/test_gpt.py::test_llm_gpt2_medium_stop_words_1gpu[streaming-use_cpp_session]": 208.1644823551178,
   "examples/test_granite.py::test_llm_granite[granite-3.0-2b-instruct-bfloat16]": 176.35465865489095,
   "examples/test_mistral.py::test_llm_mistral_v1_1gpu[mistral-7b-v0.1-float16-max_attention_window_size_4096-summarization]": 624.4467787677422,
   "examples/test_prompt_lookup.py::test_llm_prompt_lookup_1gpu[no_streaming-gpt2-use_cpp_session-use_tokens-max_matching_ngram_size_2-prompt_lookup_num_tokens_8-float16-bs2]": 208.30514740664512,
   "examples/test_recurrentgemma.py::test_llm_recurrentgemma_1gpu[use_cpp_session-recurrentgemma-2b-use_paged_cache-int4_awq-float16-enable_attn_plugin-enable_gemm_plugin]": 572.9343969132751,
   "examples/test_recurrentgemma.py::test_llm_recurrentgemma_1gpu[use_py_session-recurrentgemma-2b-flax-no_paged_cache-disable_quant-float16-enable_attn_plugin-disable_gemm_plugin]": 298.86107815708965,
   "examples/test_llm_api_with_mpi.py::test_llm_api_single_gpu_with_mpirun[TinyLlama-1.1B-Chat-v1.0]": 103.06382041191682,
   "test_e2e.py::test_llmapi_example_customize": 76.98389629460871,
   "test_e2e.py::test_llmapi_example_guided_decoding": 209.8062539859675,
   "test_e2e.py::test_llmapi_example_inference": 55.089511370286345,
   "test_e2e.py::test_llmapi_example_inference_async": 54.30802672216669,
   "test_e2e.py::test_llmapi_example_inference_async_streaming": 54.46206620475277,
   "test_e2e.py::test_llmapi_example_logits_processor": 101.52442916110158,
   "test_e2e.py::test_llmapi_example_lookahead_decoding": 111.11003456404433,
   "test_e2e.py::test_llmapi_example_multilora": 84.67327785491943,
   "test_e2e.py::test_llmapi_example_quantization": 446.02782452479005,
   "test_e2e.py::test_llmapi_quickstart": 72.54955591261387,
   "accuracy/test_cli_flow.py::TestGpt2::test_context_fmha_disabled": 150.50996276317164,
   "accuracy/test_cli_flow.py::TestLlama7B::test_auto_dtype": 429.88311998173594,
   "accuracy/test_cli_flow.py::TestStarcoder2_3B::test_auto_dtype": 191.82290547597222,
   "examples/test_bert.py::test_llm_bert_general[compare_hf-disable_remove_input_padding-disable_attention_plugin-disable_context_fmha-tp:1-pp:1-float32-RobertaModel-bert/roberta-base]": 113.30325156264007,
   "examples/test_bert.py::test_llm_bert_general[compare_hf-enable_remove_input_padding-use_attention_plugin-enable_context_fmha-tp:1-pp:1-float16-RobertaModel-bert/roberta-base]": 120.67441771924496,
   "examples/test_mamba.py::test_llm_mamba_1gpu[mamba2-130m-float16-disable_gemm_plugin]": 130.4011254440993,
   "examples/test_medusa.py::test_llm_medusa_1gpu[use_cpp_session-medusa-vicuna-7b-v1.3-4-heads-bfloat16-bs8]": 224.95245160604827,
   "examples/test_medusa.py::test_llm_medusa_1gpu[use_py_session-medusa-vicuna-7b-v1.3-4-heads-bfloat16-bs8]": 316.9145481288433,
   "examples/test_redrafter.py::test_llm_redrafter_1gpu[use_cpp_session-redrafter-vicuna-7b-v1.3-bfloat16-dl5-nb5-bs8]": 322.069238304859,
   "examples/test_redrafter.py::test_llm_redrafter_1gpu[use_py_session-redrafter-vicuna-7b-v1.3-bfloat16-dl5-nb8-bs8]": 347.0968044898473,
   "examples/test_whisper.py::test_llm_whisper_general[large-v3-disable_gemm_plugin-disable_attention_plugin-disable_weight_only-float16-nb:1-use_python_runtime]": 376.65472388314083,
   "examples/test_whisper.py::test_llm_whisper_general[large-v3-disable_gemm_plugin-enable_attention_plugin-disable_weight_only-float16-nb:1-use_python_runtime]": 210.96424189582467,
   "- t5_base for t5 baseline.\"": 200.14894059300423,
   "test_e2e.py::test_build_time_benchmark_sanity": 162.84118820587173,
   "test_e2e.py::test_llmapi_load_engine_from_build_command[llama-codellama/CodeLlama-7b-Instruct-hf]": 246.65792115405202,
   "test_e2e.py::test_mistral_e2e[use_cpp_session-remove_input_padding--]": 164.16296171024442,
   "test_e2e.py::test_mistral_e2e[use_py_session-remove_input_padding--]": 157.07205615006387,
   "accuracy/test_cli_flow.py::TestGptNext::test_auto_dtype": 217.97204774990678,
   "examples/test_medusa.py::test_llm_medusa_with_qaunt_base_model_1gpu[fp8-use_py_session-medusa-vicuna-7b-v1.3-4-heads-float16-bs1]": 235.75594696588814,
   "accuracy/test_cli_flow.py::TestGpt2::test_auto_dtype": 359.9877057634294,
   "accuracy/test_cli_flow.py::TestGpt2::test_beam_search": 378.18981846794486,
   "accuracy/test_cli_flow.py::TestGpt2::test_cuda_graph": 139.66134295240045,
   "accuracy/test_cli_flow.py::TestGpt2Medium::test_fp8": 181.35607611574233,
   "accuracy/test_cli_flow.py::TestLlama3_2_1B::test_auto_dtype": 162.29067257605493,
   "accuracy/test_cli_flow.py::TestLlama3_8BInstructGradient1048k::test_long_context": 674.971891079098,
   "accuracy/test_cli_flow.py::TestMinitron4BBase::test_fp8": 352.1536008119583,
   "accuracy/test_cli_flow.py::TestNemotronMini4BInstruct::test_fp8_prequantized": 196.69897147687152,
   "accuracy/test_cli_flow.py::TestPhi2::test_auto_dtype": 448.4716412781272,
   "accuracy/test_cli_flow.py::TestVicuna7B::test_eagle[cuda_graph-chunked_context]": 1082.8790777400136,
   "accuracy/test_cli_flow.py::TestVicuna7B::test_eagle[cuda_graph]": 879.5291580595076,
   "examples/test_chatglm.py::test_llm_glm_4_9b_single_gpu_summary[glm-4-9b-disable_weight_only]": 323.8293487201445,
   "examples/test_eagle.py::test_llm_eagle_1gpu[EAGLE-Vicuna-7B-v1.3-float16-bs1-eagle2]": 245.25481820804998,
   "examples/test_enc_dec.py::test_llm_enc_dec_mmlu[flan-t5-small-float32-tp:1-pp:1-nb:1-enable_fp8]": 1036.6409965846688,
   "examples/test_gpt.py::test_llm_minitron_fp8_with_pseudo_loras[4b]": 243.44804541300982,
   "examples/test_granite.py::test_granite_bf16_lora[granite-3.0-2b-instruct]": 176.98017238709144,
   "examples/test_llama.py::test_llama_3_x_fp8_with_bf16_lora[llama-v3-8b-instruct-hf]": 263.5484958551824,
   "examples/test_mistral.py::test_llm_mistral_nemo_minitron_fp8_quantization[Mistral-NeMo-Minitron-8B-Instruct]": 435.1071074642241,
   "examples/test_multimodal.py::test_llm_multimodal_general[Phi-3.5-vision-instruct-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]": 267.1842962158844,
   "examples/test_multimodal.py::test_llm_multimodal_general[llava-1.5-7b-hf-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]": 399.7434950321913,
   "test_e2e.py::test_benchmark_sanity_enable_fp8[gpt_350m]": 237.59561900701374,
   "test_unittests.py::test_unittests_v2[unittest/bindings]": 1088.1601313594729,
   "test_unittests.py::test_unittests_v2[unittest/trt/model_api/test_model_quantization.py]": 444.04221565648913,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_bfloat16[-attention_dp]": 126.6140753380023,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_bfloat16[-overlap_scheduler]": 122.46367594692856,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_bfloat16[mtp_nextn=2-attention_dp-cuda_graph-overlap_scheduler]": 214.85463074198924,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_bfloat16[mtp_nextn=2-cuda_graph]": 149.8972098971717,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_nvfp4[attention_dp-cuda_graph-overlap_scheduler]": 181.04260704596527,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_nvfp4[cuda_graph]": 124.14912554598413,
   "accuracy/test_llm_api_pytorch.py::TestLlama3_1_8B::test_nvfp4": 57.82179250597255,
   "test_e2e.py::test_ptp_quickstart_advanced[Llama3.1-8B-NVFP4-nvfp4-quantized/Meta-Llama-3.1-8B]": 54.82899539999198,
   "test_e2e.py::test_ptp_quickstart_advanced_eagle3[Llama-3.1-8b-Instruct-llama-3.1-model/Llama-3.1-8B-Instruct-EAGLE3-LLaMA3.1-Instruct-8B]": 52.247361588990316,
   "test_e2e.py::test_ptq_quickstart_advanced_mtp[DeepSeek-V3-Lite-BF16-DeepSeek-V3-Lite/bf16]": 99.60289056104375,
   "test_unittests.py::test_unittests_v2[unittest/_torch -k \"modeling_llama\"]": 383.36637645587325,
   "accuracy/test_cli_flow.py::TestVicuna7B::test_medusa[]": 335.9507323849248,
   "test_e2e.py::test_llmapi_exit": 35.21380679309368,
   "test_e2e.py::test_llmapi_load_engine_from_build_command_with_lora[llama-llama-models-v2/llama-v2-7b-hf]": 206.0046700872481,
   "test_e2e.py::test_llmapi_quickstart_atexit": 71.81261271703988,
   "test_e2e.py::test_trtllm_serve_multimodal_example": 209.68503899872303,
   "test_unittests.py::test_unittests_v2[unittest/api_stability]": 36.31356453150511,
   "test_unittests.py::test_unittests_v2[unittest/trt/attention/test_gpt_attention_IFB.py]": 91.86095201806165,
   "test_unittests.py::test_unittests_v2[unittest/trt/quantization]": 1143.9103821259923,
   "accuracy/test_cli_flow.py::TestLlama2_7B::test_auto_dtype": 466.4275871515274,
   "test_e2e.py::test_llmapi_chat_example": 107.07584413141012,
   "test_e2e.py::test_openai_misc_example": 268.80903728306293,
   "test_unittests.py::test_unittests_v2[unittest/llmapi/test_build_cache.py]": 33.055576127022505,
   "test_unittests.py::test_unittests_v2[unittest/trt/attention/test_gpt_attention.py -k \"partition1\"]": 77.91384115396068,
   "test_cpp.py::test_benchmarks[t5-90]": 433.7954601449892,
   "test_cpp.py::test_model[-enc_dec_language_adapter-90]": 623.6458861241117,
   "test_cpp.py::test_model[-t5-90]": 322.25090209394693,
   "test_cpp.py::test_model[fp8-llama-90]": 1675.1024751900695,
   "test_cpp.py::test_unit_tests[batch_manager-90]": 361.1391861611046,
   "test_cpp.py::test_unit_tests[common-90]": 20.09170190896839,
   "test_cpp.py::test_unit_tests[executor-90]": 488.5837896312587,
   "test_cpp.py::test_unit_tests[kernels-90]": 894.6598671339452,
   "test_cpp.py::test_unit_tests[layers-90]": 2101.663583073765,
   "test_cpp.py::test_unit_tests[runtime-90]": 1494.0379371489398,
   "test_cpp.py::test_unit_tests[thop-90]": 3.5375677570700645,
   "test_cpp.py::test_unit_tests[utils-90]": 5.673863782081753,
   "test_cpp.py::test_model[-gpt_executor-80]": 3802.0617658644915,
   "test_cpp.py::test_unit_tests[batch_manager-80]": 360.9037504121661,
   "test_cpp.py::test_unit_tests[executor-80]": 336.9986820705235,
   "test_cpp.py::test_unit_tests[layers-80]": 2112.108014985919,
   "test_cpp.py::test_unit_tests[thop-80]": 3.3378215953707695,
   "accuracy/test_cli_flow.py::TestGpt2::test_int8_kv_cache": 386.2647467160132,
   "accuracy/test_cli_flow.py::TestQwen2_7BInstruct::test_int4_awq_prequantized": 603.2285047951154,
   "accuracy/test_cli_flow.py::TestStarcoder2_15B::test_smooth_quant_ootb": 606.370930580888,
   "accuracy/test_cli_flow.py::TestTinyLlama1_1BChat::test_weight_only[int8]": 151.17010953905992,
   "test_unittests.py::test_unittests_v2[unittest/llmapi/test_llm_models.py -m \"part1\"]": 552.6703659989871,
   "accuracy/test_cli_flow.py::TestGpt2::test_beam_search_large": 751.082179825753,
   "test_e2e.py::test_gpt3_175b_1layers_build_only": 137.2015721425414,
   "test_e2e.py::test_llmapi_server_example": 112.31814356148243,
   "test_e2e.py::test_openai_chat_multimodal_example": 229.08619002997875,
   "test_e2e.py::test_trtllm_bench_request_rate_and_concurrency[enable_concurrency-]": 237.8939011550974,
   "test_unittests.py::test_unittests_v2[unittest/trt/attention/test_gpt_attention.py -k \"partition3\"]": 73.82871875306591,
   "test_unittests.py::test_unittests_v2[unittest/trt/functional]": 617.5787682400551,
   "test_unittests.py::test_unittests_v2[unittest/trt/model/test_mistral.py]": 338.80633844062686,
   "accuracy/test_cli_flow.py::TestLlama3_2_1B::test_int4_awq_int8_kv_cache": 607.2866316649597,
   "accuracy/test_cli_flow.py::TestLlama3_2_1B::test_smooth_quant_ootb": 221.91259149694815,
   "accuracy/test_cli_flow.py::TestLlama3_8BInstruct::test_int8_gptq": 579.1511958378833,
   "accuracy/test_cli_flow.py::TestTinyLlama1_1BChat::test_weight_only[int4]": 167.0793503120076,
   "test_unittests.py::test_unittests_v2[unittest/trt/attention/test_sage_attention.py unittest/llmapi/test_llm_download.py unittest/llmapi/test_llm_kv_cache_events.py unittest/llmapi/test_mpi_session.py unittest/trt/model/redrafter unittest/trt/model/test_phi.py unittest/trt/model/test_unet.py unittest/trt/python_plugin unittest/tools unittest/utils unittest/others]": 1013.9779937970452,
   "accuracy/test_cli_flow.py::TestLlama2_7B::test_fp8_gemm_swiglu_plugin": 334.09972435212694,
   "examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-flan-t5-small-float32-enable_gemm_plugin-enable_attention_plugin-enable_paged_kv_cache-tp:1-pp:1-nb:1-enable_fp8]": 346.77571318508126,
   "examples/test_enc_dec.py::test_llm_enc_dec_mmlu[flan-t5-small-float32-tp:1-pp:1-nb:1-disable_fp8]": 370.9559136838652,
   "examples/test_redrafter.py::test_llm_redrafter_1gpu[use_cpp_session-redrafter-vicuna-7b-v1.3-bfloat16-dl5-nb8-bs8]": 304.5168183001224,
   "test_e2e.py::test_trtllm_bench_iteration_log[PyTorch-non-streaming-meta-llama/Llama-3.1-8B-llama-3.1-model/Meta-Llama-3.1-8B]": 136.70510453986935,
   "test_e2e.py::test_trtllm_bench_request_rate_and_concurrency[enable_concurrency-enable_request_rate]": 196.38372873608023,
   "accuracy/test_cli_flow.py::TestLlama2_7B::test_weight_sparsity": 584.3506899178028,
   "accuracy/test_cli_flow.py::TestPhi3Mini128kInstruct::test_auto_dtype": 249.65205231308937,
   "examples/test_granite.py::test_llm_granite[granite-3.0-1b-a400m-instruct-bfloat16]": 121.18374785780907,
   "examples/test_medusa.py::test_llm_medusa_1gpu[use_cpp_session-medusa-vicuna-7b-v1.3-4-heads-bfloat16-bs1]": 238.16604533046484,
   "examples/test_multimodal.py::test_llm_multimodal_general[llava-v1.6-mistral-7b-hf-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]": 264.67656864225864,
   "examples/test_multimodal.py::test_llm_multimodal_general[llava-v1.6-mistral-7b-hf-vision-trtllm-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]": 241.55408930033445,
   "examples/test_prompt_lookup.py::test_llm_prompt_lookup_1gpu[streaming-gpt2-use_cpp_session-use_tokens-max_matching_ngram_size_2-prompt_lookup_num_tokens_8-float16-bs2]": 195.30973169207573,
   "examples/test_qwen2audio.py::test_llm_qwen2audio_single_gpu[qwen2_audio_7b_instruct]": 350.21612004190683,
   "test_cpp.py::test_benchmarks[bart-90]": 289.665924933739,
   "test_cpp.py::test_model[-bart-90]": 406.8593009216711,
   "test_cpp.py::test_model[-gpt-80]": 2575.5351933650672,
   "test_cpp.py::test_model[-gpt_tests-80]": 1818.1335739046335,
   "test_cpp.py::test_unit_tests[common-80]": 20.21354992315173,
   "test_cpp.py::test_unit_tests[kernels-80]": 824.8142545670271,
   "test_cpp.py::test_unit_tests[runtime-80]": 1481.4635888151824,
   "test_cpp.py::test_unit_tests[utils-80]": 5.492456428706646,
   "accuracy/test_cli_flow.py::TestGpt2::test_attention_ootb": 433.5440105088055,
   "accuracy/test_cli_flow.py::TestPhi3Small8kInstruct::test_auto_dtype": 627.7117496980354,
   "examples/test_gpt.py::test_llm_gpt2_next_prompt_tuning[use_cpp_session-tp1]": 528.5754495761357,
   "examples/test_granite.py::test_granite_bf16_lora[granite-3.0-1b-a400m-instruct]": 167.5465040979907,
   "examples/test_multimodal.py::test_llm_multimodal_general[kosmos-2-pp:1-tp:1-float16-bs:1-cpp_e2e:True-nb:1]": 378.847409482114,
   "accuracy/test_cli_flow.py::TestLlama3_1_8B::test_fp8_rowwise_meta_recipe": 635.4923002601136,
   "accuracy/test_cli_flow.py::TestPhi3Small128kInstruct::test_auto_dtype": 596.1179581009783,
   "examples/test_llama.py::test_llm_llama_v2_lora_1gpu[chinese-llama-2-lora-13b-llama-v2-13b-hf-lora_fp16-base_fp16]": 1059.5779938041233,
   "examples/test_nemotron_nas.py::test_nemotron_nas_summary_1gpu[DeciLM-7B]": 309.048251519911,
   "examples/test_phi.py::test_llm_phi_lora_1gpu[Phi-3-mini-4k-instruct-ru-lora-Phi-3-mini-4k-instruct-lora_fp16-base_fp16]": 259.64929464203306,
   "test_unittests.py::test_unittests_v2[unittest/trt/attention/test_gpt_attention.py -k \"partition0\"]": 75.63153928238899,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_bfloat16[-]": 521.511109575993,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_bfloat16[-attention_dp-cuda_graph-overlap_scheduler]": 275.7205912599893,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_bfloat16[-cuda_graph]": 205.65720540299662,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_bfloat16[mtp_nextn=2-]": 186.7698321180069,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_bfloat16[mtp_nextn=2-attention_dp]": 188.98230919099296,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_bfloat16[mtp_nextn=2-overlap_scheduler]": 189.30778573200223,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_fp8_block_scales[-]": 572.3111863140948,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_fp8_block_scales[-attention_dp]": 218.61606945516542,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_fp8_block_scales[-overlap_scheduler]": 178.214486093726,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_fp8_block_scales[mtp_nextn=2-attention_dp-cuda_graph-overlap_scheduler]": 339.4452533577569,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_fp8_block_scales[mtp_nextn=2-cuda_graph]": 229.85118352621794,
   "accuracy/test_llm_api_pytorch.py::TestLlama3_1_8BInstruct::test_bfloat16[attn_backend=FLASHINFER-torch_compile]": 458.30828762054443,
   "accuracy/test_llm_api_pytorch.py::TestLlama3_1_8BInstruct::test_bfloat16[attn_backend=TRTLLM-torch_compile]": 268.0337800453417,
   "accuracy/test_llm_api_pytorch.py::TestLlama3_1_8BInstruct::test_fp8[-attn_backend=FLASHINFER-]": 219.2082560150884,
   "accuracy/test_llm_api_pytorch.py::TestLlama3_1_8BInstruct::test_fp8[-attn_backend=TRTLLM-]": 185.08534214179963,
   "accuracy/test_llm_api_pytorch.py::TestLlama3_1_8BInstruct::test_fp8[fp8kv-attn_backend=FLASHINFER-]": 295.71494576195255,
   "accuracy/test_llm_api_pytorch.py::TestLlama3_1_8BInstruct::test_fp8[fp8kv-attn_backend=TRTLLM-]": 187.1975629827939,
   "disaggregated/test_disaggregated.py::test_disaggregated_deepseek_v3_lite_fp8_tp1_single_gpu_mtp[DeepSeek-V3-Lite-fp8]": 131.82164152292535,
   "disaggregated/test_disaggregated_single_gpu.py::test_disaggregated_llama_context_capacity[False-False-DeepSeek-V3-Lite-fp8/fp8]": 453.19822712801397,
   "disaggregated/test_disaggregated_single_gpu.py::test_disaggregated_simple_deepseek[False-False-DeepSeek-V3-Lite-fp8/fp8]": 59.055865885689855,
   "disaggregated/test_disaggregated_single_gpu.py::test_disaggregated_simple_deepseek[True-False-DeepSeek-V3-Lite-fp8/fp8]": 82.1424966850318,
   "disaggregated/test_disaggregated_single_gpu.py::test_disaggregated_simple_llama[False-False-TinyLlama-1.1B-Chat-v1.0]": 32.81478118337691,
   "disaggregated/test_disaggregated_single_gpu.py::test_disaggregated_simple_llama[True-False-TinyLlama-1.1B-Chat-v1.0]": 49.68006537621841,
   "test_e2e.py::test_trtllm_bench_pytorch_backend_sanity[meta-llama/Llama-3.1-8B-llama-3.1-8b-instruct-hf-fp8-True-True]": 100.39274466224015,
   "test_unittests.py::test_unittests_v2[unittest/_torch/modeling -k \"modeling_nemotron\"]": 1172.453643232584,
   "test_unittests.py::test_unittests_v2[unittest/_torch/multi_gpu_modeling -k \"deepseek\"]": 97.60818650666624,
   "accuracy/test_cli_flow.py::TestLlama3_8BInstruct::test_nvfp4": 301.4283516310388,
   "test_unittests.py::test_unittests_v2[unittest/trt/attention/test_gpt_attention.py -k \"trtllm_gen\"]": 338.4560270620277,
   "test_cache.py::test_cache_sanity": 0.0002712220884859562,
   "test_unittests.py::test_unittests_v2[unittest/trt/attention/test_gpt_attention.py -k \"partition2\"]": 70.17422695807181,
   "test_unittests.py::test_unittests_v2[unittest/trt/model/test_gpt_e2e.py]": 792.6822164891055,
   "accuracy/test_llm_api.py::TestLlama3_1_8B::test_fp8_rowwise": 624.4882775419392,
   "test_e2e.py::test_llmapi_example_medusa_decoding_use_modelopt": 504.76980912685394,
   "accuracy/test_cli_flow.py::TestGpt2::test_weight_streaming_ootb": 206.36854852596298,
   "accuracy/test_cli_flow.py::TestLlama7B::test_streamingllm": 551.792699676007,
   "accuracy/test_cli_flow.py::TestVicuna7B::test_eagle[cuda_graph-typical_acceptance]": 413.2656224630773,
   "test_e2e.py::test_llmapi_load_engine_from_build_command[llama-llama-models/llama-7b-hf]": 198.2025441341102,
   "test_unittests.py::test_unittests_v2[unittest/trt/model/test_mamba.py]": 104.14999498892576,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_nvfp4[]": 156.27158334900741,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_nvfp4[attention_dp]": 107.45846718399844,
   "accuracy/test_llm_api_pytorch.py::TestDeepSeekV3Lite::test_nvfp4[overlap_scheduler]": 110.33642856699589,
   "test_e2e.py::test_ptp_quickstart_advanced[Llama3.1-8B-FP8-llama-3.1-model/Llama-3.1-8B-Instruct-FP8]": 72.22622085400508,
   "test_e2e.py::test_ptp_quickstart_advanced_mixed_precision": 71.89974328200333,
   "test_unittests.py::test_unittests_v2[unittest/_torch/auto_deploy/unit/singlegpu]": 748.6500213332474,
   "test_unittests.py::test_unittests_v2[unittest/_torch/speculative/test_eagle3.py]": 159.04478430299787,
   "examples/test_bert.py::test_llm_bert_general[compare_hf-enable_remove_input_padding-use_attention_plugin-enable_context_fmha-tp:1-pp:1-float16-BertModel-bert/bert-base-uncased]": 123.04115173965693,
   "test_unittests.py::test_unittests_v2[unittest/llmapi/test_llm_perf_evaluator.py]": 122.12052960321307,
   "test_unittests.py::test_unittests_v2[unittest/trt/model/test_llama.py]": 1613.379823461175,
   "test_e2e.py::test_ptp_quickstart_bert[TRTLLM-BertForSequenceClassification-bert/bert-base-uncased-yelp-polarity]": 21.29602987895487,
   "test_e2e.py::test_ptp_quickstart_bert[VANILLA-BertForSequenceClassification-bert/bert-base-uncased-yelp-polarity]": 18.762104595953133,
   "test_e2e.py::test_ptp_quickstart_multimodal[NVILA-8B-FP16-vila/NVILA-8B-video]": 239.917054744903,
   "test_e2e.py::test_ptp_quickstart_multimodal[llava-v1.6-mistral-7b-llava-v1.6-mistral-7b-hf-image]": 129.3945918257814,
   "test_e2e.py::test_ptp_quickstart_multimodal[qwen2-vl-7b-instruct-Qwen2-VL-7B-Instruct-video]": 108.2345735321287,
   "test_e2e.py::test_ptp_quickstart_multimodal[qwen2.5-vl-7b-instruct-Qwen2.5-VL-7B-Instruct-image]": 105.60021635401063,
   "test_e2e.py::test_ptp_quickstart_multimodal[qwen2.5-vl-7b-instruct-Qwen2.5-VL-7B-Instruct-video]": 108.97071609413251,
   "test_unittests.py::test_unittests_v2[unittest/_torch/modeling -k \"modeling_mllama\"]": 836.1367770433426,
   "test_unittests.py::test_unittests_v2[unittest/_torch/modeling -k \"modeling_nemotron_nas\"]": 601.3914929665625,
   "test_unittests.py::test_unittests_v2[unittest/_torch/modeling -k \"modeling_out_of_tree\"]": 103.82364434748888,
   "test_unittests.py::test_unittests_v2[unittest/_torch/modeling -k \"modeling_qwen\"]": 655.737279240042,
   "test_unittests.py::test_unittests_v2[unittest/_torch/modeling -k \"modeling_vila\"]": 80.0136424973607,
   "accuracy/test_cli_flow.py::TestGemma2_9BIt::test_auto_dtype": 819.1235056649894,
   "accuracy/test_cli_flow.py::TestLlama3_1_8B::test_autoq": 970.7694670706987,
   "accuracy/test_cli_flow.py::TestLlama3_1_8B::test_fp8": 377.5798255498521,
   "accuracy/test_cli_flow.py::TestLlama3_8BInstructGradient1048k::test_long_context_ppl": 824.5897679440677,
   "accuracy/test_cli_flow.py::TestTinyLlama1_1BChat::test_float32": 187.59073625179008,
   "examples/test_eagle.py::test_llm_eagle_1gpu[EAGLE-Vicuna-7B-v1.3-float16-bs1-eagle1]": 267.8851871159859,
   "examples/test_eagle.py::test_llm_eagle_1gpu_modelopt_ckpt[llama3.1-eagle-8b-hf_v0.5-float16-bs8]": 601.0534219346009,
   "examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-bart-large-cnn-float16-enable_gemm_plugin-enable_attention_plugin-enable_paged_kv_cache-tp:1-pp:1-nb:1-enable_fp8]": 2837.3990841666237,
   "examples/test_multimodal.py::test_llm_multimodal_general[Phi-3-vision-128k-instruct-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]": 326.9359554871917,
   "examples/test_multimodal.py::test_llm_multimodal_general[Phi-4-multimodal-instruct-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]": 838.8300332771614,
   "examples/test_multimodal.py::test_llm_multimodal_general[fuyu-8b-pp:1-tp:1-float16-bs:1-cpp_e2e:True-nb:1]": 372.99994897376746,
   "examples/test_redrafter.py::test_llm_redrafter_1gpu[use_py_session-redrafter-vicuna-7b-v1.3-bfloat16-dl5-nb5-bs8]": 331.4244818720035,
   "test_e2e.py::test_benchmark_sanity_enable_fp8[llama_7b]": 247.66422768030316,
   "test_unittests.py::test_unittests_v2[unittest/trt/attention/test_bert_attention.py]": 90.87498506298289,
   "disaggregated/test_disaggregated.py::test_disaggregated_cuda_graph[TinyLlama-1.1B-Chat-v1.0]": 107.8794369995594,
   "disaggregated/test_disaggregated.py::test_disaggregated_mixed[TinyLlama-1.1B-Chat-v1.0]": 67.66113496571779,
   "disaggregated/test_disaggregated.py::test_disaggregated_overlap[TinyLlama-1.1B-Chat-v1.0]": 99.3982776850462,
   "disaggregated/test_disaggregated.py::test_disaggregated_single_gpu_with_mpirun[TinyLlama-1.1B-Chat-v1.0]": 67.57336937636137,
   "accuracy/test_cli_flow.py::TestGpt2::test_weight_only[int8]": 357.54412304982543,
   "test_cpp.py::test_model[-eagle-86]": 796.9246113337576,
   "test_cpp.py::test_model[-mamba-86]": 881.4843314252794,
   "test_cpp.py::test_model[-medusa-86]": 596.4133048951626,
   "test_cpp.py::test_model[-redrafter-86]": 327.25269604846835,
   "test_unittests.py::test_unittests_v2[unittest/llmapi/test_llm_pytorch.py]": 503.03602447733283,
   "examples/test_llama.py::test_llm_llama_v3_1_1node_single_gpu[llama-3.2-1b-disable_fp8]": 519.357479127124,
   "test_unittests.py::test_unittests_v2[unittest/llmapi/test_llm_models.py -m \"part0\"]": 157.88666922226548,
   "accuracy/test_cli_flow.py::TestMinitron4BBase::test_auto_dtype": 229.43771601002663,
   "accuracy/test_llm_api.py::TestQwen2_5_1_5BInstruct::test_weight_only": 409.5637682341039,
   "examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-bart-large-cnn-float32-enable_gemm_plugin-enable_attention_plugin-enable_paged_kv_cache-tp:1-pp:1-nb:2-disable_fp8]": 252.26230971235782,
   "examples/test_llama.py::test_llm_llama_1gpu_batched_beam_search[llama-7b]": 157.81341629568487,
   "examples/test_multimodal.py::test_llm_multimodal_general[deplot-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:1]": 239.49694572761655,
   "test_unittests.py::test_unittests_v2[unittest/trt/model/test_gpt.py -k \"partition0\"]": 261.6742676384747,
   "test_unittests.py::test_unittests_v2[unittest/trt/model/test_gpt.py -k \"partition3\"]": 364.01926339790225,
   "test_unittests.py::test_unittests_v2[unittest/trt/model/test_nemotron_nas.py -k \"not fp8\"]": 855.5884895883501,
   "examples/test_bert.py::test_llm_bert_general[compare_hf-disable_remove_input_padding-disable_attention_plugin-disable_context_fmha-tp:1-pp:1-float32-BertModel-bert/bert-base-uncased]": 111.40550503134727,
   "examples/test_mamba.py::test_llm_mamba_1gpu[mamba-130m-float16-disable_gemm_plugin]": 133.30427036434412,
   "examples/test_mamba.py::test_llm_mamba_1gpu[mamba-130m-float16-enable_gemm_plugin]": 114.74723817408085,
   "examples/test_mamba.py::test_llm_mamba_1gpu[mamba-codestral-7B-v0.1-float16-disable_gemm_plugin]": 402.5346692726016,
   "test_e2e.py::test_llmapi_load_ckpt_from_convert_command": 194.35754750296474,
   "test_e2e.py::test_mistral_e2e[use_py_session---]": 164.14864564687014,
   "test_unittests.py::test_unittests_v2[unittest/_torch/modeling -k \"modeling_qwen_moe\"]": 464.1027664169669,
   "test_cpp.py::test_benchmarks[gpt-80]": 1376.4873856268823,
   "test_cpp.py::test_model[-gpt_session-80]": 1751.2419156692922,
   "accuracy/test_cli_flow.py::TestLlama2_7B::test_fp8_gemm_plugin": 329.74231013609096,
   "accuracy/test_cli_flow.py::TestLongAlpaca7B::test_multiblock_aggressive": 452.46869553090073,
   "examples/test_gemma.py::test_llm_gemma_1gpu_summary_vswa[gemma-3-1b-it-other-bfloat16-8]": 107.23580439691432,
   "examples/test_llama.py::test_llama_3_x_fp8_with_bf16_lora[llama-3.2-1b]": 91.68686148803681,
   "examples/test_multimodal.py::test_llm_fp8_multimodal_general[fp8-fp8-cnn_dailymail-Qwen2-VL-7B-Instruct-pp:1-tp:1-bfloat16-bs:1-cpp_e2e:False]": 302.39953589695506,
   "test_unittests.py::test_unittests_v2[unittest/trt/functional/test_moe.py]": 215.25935298600234,
   "accuracy/test_cli_flow.py::TestLlama3_2_1B::test_weight_streaming[0.1]": 569.1722077839077,
   "accuracy/test_cli_flow.py::TestPhi3Mini4kInstruct::test_auto_dtype": 262.3816612251103,
   "examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-byt5-small-float32-enable_gemm_plugin-enable_attention_plugin-enable_paged_kv_cache-tp:1-pp:1-nb:1-disable_fp8]": 258.29867374897003,
   "examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-t5-small-float32-enable_gemm_plugin-enable_attention_plugin-enable_paged_kv_cache-tp:1-pp:1-nb:1-disable_fp8]": 241.74308391287923,
   "test_unittests.py::test_unittests_v2[unittest/trt/model/test_gpt.py -k \"other\"]": 143.04308335110545,
   "test_unittests.py::test_unittests_v2[unittest/trt/model/test_gpt.py -k \"partition1\"]": 302.48656964302063,
   "test_unittests.py::test_unittests_v2[unittest/trt/model/test_gpt.py -k \"partition2\"]": 392.06817293167114,
   "examples/test_llama.py::test_llm_llama_v1_1gpu_kv_cache_reuse_with_prompt_table[llama-7b]": 1019.8532189140096,
   "examples/test_llama.py::test_llm_llama_v3_dora_1gpu[commonsense-llama-v3-8b-dora-r32-llama-v3-8b-hf-base_fp16]": 343.1759448489174,
   "accuracy/test_cli_flow.py::TestLlama2_7B::test_fp8_low_latency_gemm_plugin": 603.1894486009842,
   "examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-t5-small-float32-enable_gemm_plugin-enable_attention_plugin-enable_paged_kv_cache-tp:1-pp:1-nb:1-enable_fp8]": 583.56732430798,
   "examples/test_multimodal.py::test_llm_multimodal_general[Llama-3.2-11B-Vision-pp:1-tp:1-bfloat16-bs:8-cpp_e2e:False-nb:1]": 413.9328626289498,
   "test_e2e.py::test_trtllm_bench_iteration_log[PyTorch-streaming-meta-llama/Llama-3.1-8B-llama-3.1-model/Meta-Llama-3.1-8B]": 155.39102740597446,
   "test_unittests.py::test_unittests_v2[unittest/trt/quantization/test_weight_only_groupwise_quant_matmul.py]": 261.21993328107055,
   "accuracy/test_cli_flow.py::TestGpt2::test_weight_only[int4]": 351.4742647688836,
   "accuracy/test_cli_flow.py::TestLlama3_2_1B::test_smooth_quant": 183.48757565952837,
   "accuracy/test_cli_flow.py::TestTinyLlama1_1BChat::test_weight_only_manage_weights[int4]": 153.53113883174956,
   "test_unittests.py::test_unittests_v2[unittest/llmapi/test_llm.py -m \"part0\"]": 1603.2002695798874,
   "examples/test_gpt.py::test_llm_gpt2_next_prompt_tuning[use_py_session-tp1]": 454.1941373560112,
   "examples/test_qwen.py::test_llm_qwen1_5_7b_single_gpu_lora[qwen1.5_7b_chat-Qwen1.5-7B-Chat-750Mb-lora]": 270.12795097893104,
   "accuracy/test_cli_flow.py::TestLlama3_2_1B::test_smooth_quant_ootb_manage_weights": 453.83340549701825,
   "accuracy/test_cli_flow.py::TestTinyLlama1_1BChat::test_weight_only_int8_kv_cache[int8]": 192.0788443570491,
   "test_unittests.py::test_unittests_v2[unittest/llmapi/test_executor.py]": 374.7509622410871,
   "test_unittests.py::test_unittests_v2[unittest/llmapi/test_llm.py -m \"not part0\"]": 1900.7531859970186,
   "test_unittests.py::test_unittests_v2[unittest/llmapi/test_llm_models.py -m \"not (part0 or part1)\"]": 808.0638768831268,
   "examples/test_llama.py::test_llm_llama_1gpu[llama-3.1-8b-instruct-hf-fp8-enable_fp8-float16-summarization-nb:1]": 869.9131828863174,
   "accuracy/test_llm_api.py::TestQwen2_7BInstruct::test_weight_only": 627.899879463017,
   "examples/test_draft_target_model.py::test_llm_draft_target_model_1gpu[no_streaming-gpt2-use_cpp_session-use_logits-draft_len_4-float16-bs2]": 248.11730453372002,
   "examples/test_draft_target_model.py::test_llm_draft_target_model_1gpu[no_streaming-gpt2-use_cpp_session-use_tokens-draft_len_4-float16-bs2]": 243.84544993937016,
   "examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-bart-large-cnn-bfloat16-enable_gemm_plugin-enable_attention_plugin-disable_paged_kv_cache-tp:1-pp:1-nb:1-disable_fp8]": 256.5266339369118,
   "examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-flan-t5-small-float32-disable_gemm_plugin-disable_attention_plugin-disable_paged_kv_cache-tp:1-pp:1-nb:1-disable_fp8]": 231.1847080476582,
   "examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-flan-t5-small-float32-disable_gemm_plugin-enable_attention_plugin-disable_paged_kv_cache-tp:1-pp:1-nb:1-disable_fp8]": 217.01890316978097,
   "examples/test_exaone.py::test_llm_exaone_1gpu[disable_weight_only-exaone_3.0_7.8b_instruct-float16-nb:1]": 369.94583523645997,
   "examples/test_exaone.py::test_llm_exaone_1gpu[disable_weight_only-exaone_deep_2.4b-float16-nb:4]": 239.6594509370625,
   "examples/test_gpt.py::test_llm_gpt2_medium_1gpu[non_streaming-use_cpp_session-enable_gemm_plugin]": 114.35463477298617,
   "examples/test_gpt.py::test_llm_gpt2_medium_1gpu[streaming-use_cpp_session-enable_gemm_plugin]": 113.55023346096277,
   "examples/test_gpt.py::test_llm_gpt2_medium_bad_words_1gpu[non_streaming-use_cpp_session]": 192.86209728568792,
   "examples/test_gpt.py::test_llm_gpt2_medium_bad_words_1gpu[non_streaming-use_py_session]": 193.82449104636908,
   "examples/test_gpt.py::test_llm_gpt2_medium_stop_words_1gpu[non_streaming-use_py_session]": 193.0897208377719,
   "examples/test_llama.py::test_llm_llama_v2_1gpu_auto_parallel[llama-v2-7b-hf]": 548.5335142575204,
   "examples/test_mistral.py::test_llm_mistral_v1_1gpu[mistral-7b-v0.1-float16-max_attention_window_size_4096-summarization_long]": 448.42280792817473,
   "accuracy/test_cli_flow.py::TestLlama3_8BInstruct::test_auto_dtype": 383.40567043598276,
   "accuracy/test_cli_flow.py::TestLlama3_8BInstruct::test_fp8": 253.8005797819933,
   "accuracy/test_cli_flow.py::TestMixtral8x7B::test_nvfp4_prequantized": 306.4924998950446,
   "test_unittests.py::test_unittests_v2[unittest/trt/functional/test_fp4_gemm.py]": 200.7020942789968,
   "accuracy/test_cli_flow.py::TestPhi3_5MiniInstruct::test_auto_dtype": 507.6678144596517,
   "accuracy/test_cli_flow.py::TestQwen2_0_5BInstruct::test_weight_only": 169.9687753394246,
   "examples/test_draft_target_model.py::test_llm_draft_target_model_1gpu[streaming-gpt2-use_cpp_session-use_logits-draft_len_4-float16-bs2]": 271.3601300008595,
   "examples/test_draft_target_model.py::test_llm_draft_target_model_1gpu[streaming-gpt2-use_cpp_session-use_tokens-draft_len_4-float16-bs2]": 264.1195522621274,
   "examples/test_enc_dec.py::test_llm_enc_dec_general[compare_hf-bart-large-cnn-bfloat16-enable_gemm_plugin-enable_attention_plugin-enable_paged_kv_cache-tp:1-pp:1-nb:1-disable_fp8]": 348.60860240086913,
   "examples/test_internlm.py::test_llm_internlm2_7b_1node_1gpu[bfloat16-enable_context_fmha-enable_gemm_plugin-enable_attention_plugin-nb:2]": 270.16639855131507,
   "examples/test_mistral.py::test_llm_mistral_v1_1gpu[mistral-7b-v0.1-float16-max_attention_window_size_4096-chunked_summarization_long]": 425.6762716732919,
   "examples/test_multimodal.py::test_llm_multimodal_general[Qwen2-VL-7B-Instruct-pp:1-tp:1-float16-bs:1-cpp_e2e:False-nb:4]": 681.2129635512829
}
